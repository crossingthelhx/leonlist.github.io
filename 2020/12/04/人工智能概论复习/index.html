<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>人工智能概论复习 | Leonlist's Blog</title><meta name="description" content="人工智能概论学习，复习笔记"><meta name="keywords" content="人工智能"><meta name="author" content="Leonlist"><meta name="copyright" content="Leonlist"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/logo.jpg"><link rel="canonical" href="http://yoursite.com/2020/12/04/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%A6%82%E8%AE%BA%E5%A4%8D%E4%B9%A0/"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//fonts.googleapis.com" crossorigin="crossorigin"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta property="og:type" content="article"><meta property="og:title" content="人工智能概论复习"><meta property="og:url" content="http://yoursite.com/2020/12/04/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%A6%82%E8%AE%BA%E5%A4%8D%E4%B9%A0/"><meta property="og:site_name" content="Leonlist's Blog"><meta property="og:description" content="人工智能概论学习，复习笔记"><meta property="og:image" content="https://i.loli.net/2019/11/10/T7Mu8Aod3egmC4Q.png"><meta property="article:published_time" content="2020-12-04T14:49:37.000Z"><meta property="article:modified_time" content="2020-12-20T09:12:15.545Z"><meta name="twitter:card" content="summary"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web&amp;display=swap"><script>var GLOBAL_CONFIG = { 
  root: '/',
  hexoversion: '5.1.1',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  bookmark: {
    message_prev: 'Press',
    message_next: 'to bookmark this page'
  },
  runtime: '',
  last_push_date: {"zeroDay":"Today","suffix":"days ago"},
  copyright: undefined,
  ClickShowText: undefined,
  medium_zoom: false,
  fancybox: true,
  Snackbar: undefined,
  justifiedGallery: {
    js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
    css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
  },
  baiduPush: false,
  isPhotoFigcaption: false,
  islazyload: true,
  isanchor: false
};

var saveToLocal = {
  set: function setWithExpiry(key, value, ttl) {
      const now = new Date()
      const expiryDay = ttl * 86400000
      const item = {
        value: value,
        expiry: now.getTime() + expiryDay,
      }
      localStorage.setItem(key, JSON.stringify(item))
    },
  
  get: function getWithExpiry(key) {
    const itemStr = localStorage.getItem(key)

    if (!itemStr) {
      return undefined
    }
    const item = JSON.parse(itemStr)
    const now = new Date()

    if (now.getTime() > item.expiry) {
      localStorage.removeItem(key)
      return undefined
    }
    return item.value
  }
}</script><script id="config_change">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isSidebar: true,
  postUpdate: '2020-12-20 17:12:15'
}</script><noscript><style type="text/css">
#nav {
  opacity: 1
}
.justified-gallery img {
  opacity: 1
}
</style></noscript><script>var activateDarkMode = function () {
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null) {
    document.querySelector('meta[name="theme-color"]').setAttribute('content', '#000')
  }
}
var activateLightMode = function () {
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null) {
    document.querySelector('meta[name="theme-color"]').setAttribute('content', '#fff')
  }
}

var autoChangeMode = 'false'
var t = saveToLocal.get('theme')
if (autoChangeMode === '1') {
  var isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
  var isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
  var isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
  var hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

  if (t === undefined) {
    if (isLightMode) activateLightMode()
    else if (isDarkMode) activateDarkMode()
    else if (isNotSpecified || hasNoSupport) {
      console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
      var now = new Date()
      var hour = now.getHours()
      var isNight = hour <= 6 || hour >= 18
      isNight ? activateDarkMode() : activateLightMode()
    }
    window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
      if (saveToLocal.get('theme') === undefined) {
        e.matches ? activateDarkMode() : activateLightMode()
      }
    })
  } else if (t === 'light') activateLightMode()
  else activateDarkMode()
} else if (autoChangeMode === '2') {
  now = new Date()
  hour = now.getHours()
  isNight = hour <= 6 || hour >= 18
  if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode()
} else {
  if (t === 'dark') activateDarkMode()
  else if (t === 'light') activateLightMode()
}</script><meta name="generator" content="Hexo 5.1.1"></head><body><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" data-lazy-src="/img/logo.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">Articles</div><div class="length_num">34</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">Tags</div><div class="length_num">15</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">Categories</div><div class="length_num">5</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于</span></a></div></div></div></div><div id="body-wrap"><div id="sidebar"><i class="fas fa-arrow-right on" id="toggle-sidebar"></i><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%AF%BC%E8%AE%BA"><span class="toc-number">1.</span> <span class="toc-text">导论</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0"><span class="toc-number">2.</span> <span class="toc-text">统计学习</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8B%9F%E5%90%88%E6%95%88%E6%9E%9C%E6%A3%80%E9%AA%8C"><span class="toc-number">2.1.</span> <span class="toc-text">拟合效果检验</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BC%B0%E8%AE%A1%E7%B3%BB%E6%95%B0"><span class="toc-number">2.1.1.</span> <span class="toc-text">估计系数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AF%84%E4%BC%B0%E7%B3%BB%E6%95%B0%E4%BC%B0%E8%AE%A1%E5%80%BC%E7%9A%84%E5%87%86%E7%A1%AE%E6%80%A7"><span class="toc-number">2.1.2.</span> <span class="toc-text">评估系数估计值的准确性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AF%84%E4%BB%B7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%87%86%E7%A1%AE%E6%80%A7"><span class="toc-number">2.1.3.</span> <span class="toc-text">评价模型的准确性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BC%B0%E8%AE%A1%E5%9B%9E%E5%BD%92%E7%B3%BB%E6%95%B0"><span class="toc-number">2.1.4.</span> <span class="toc-text">估计回归系数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%80%E4%BA%9B%E9%87%8D%E8%A6%81%E9%97%AE%E9%A2%98"><span class="toc-number">2.1.5.</span> <span class="toc-text">一些重要问题</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%93%8D%E5%BA%94%E5%8F%98%E9%87%8F%E5%92%8C%E9%A2%84%E6%B5%8B%E5%8F%98%E9%87%8F%E4%B9%8B%E9%97%B4%E6%98%AF%E5%90%A6%E6%9C%89%E5%85%B3%E7%B3%BB%EF%BC%9F"><span class="toc-number">2.1.5.1.</span> <span class="toc-text">响应变量和预测变量之间是否有关系？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%A2%84%E6%B5%8B%E5%8F%98%E9%87%8F%E4%B8%8E%E5%93%8D%E5%BA%94%E5%8F%98%E9%87%8F%E7%9A%84%E5%85%B3%E7%B3%BB"><span class="toc-number">2.1.5.2.</span> <span class="toc-text">预测变量与响应变量的关系</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%8B%9F%E5%90%88%E7%A8%8B%E5%BA%A6"><span class="toc-number">2.1.5.3.</span> <span class="toc-text">模型的拟合程度</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E9%A2%84%E6%B5%8B%E5%80%BC%EF%BC%8C%E9%A2%84%E6%B5%8B%E7%9A%84%E5%87%86%E7%A1%AE%E7%A8%8B%E5%BA%A6%E5%A6%82%E4%BD%95%EF%BC%9F"><span class="toc-number">2.1.5.4.</span> <span class="toc-text">如何预测值，预测的准确程度如何？</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%88%86%E7%B1%BB"><span class="toc-number">3.</span> <span class="toc-text">分类</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B%E5%9B%9E%E5%BD%92"><span class="toc-number">3.1.</span> <span class="toc-text">逻辑斯谛回归</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B"><span class="toc-number">3.1.1.</span> <span class="toc-text">逻辑斯谛回归模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BC%B0%E8%AE%A1%E5%9B%9E%E5%BD%92%E7%B3%BB%E6%95%B0-1"><span class="toc-number">3.1.2.</span> <span class="toc-text">估计回归系数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%9A%E5%85%83%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B%E5%9B%9E%E5%BD%92"><span class="toc-number">3.1.3.</span> <span class="toc-text">多元逻辑斯谛回归</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BA%BF%E6%80%A7%E5%88%A4%E5%88%AB%E5%88%86%E6%9E%90"><span class="toc-number">3.2.</span> <span class="toc-text">线性判别分析</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%AE%9A%E7%90%86"><span class="toc-number">3.2.1.</span> <span class="toc-text">贝叶斯定理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#p-1%E7%9A%84%E7%BA%BF%E6%80%A7%E5%88%A4%E5%88%AB%E5%88%86%E6%9E%90"><span class="toc-number">3.2.2.</span> <span class="toc-text">p&#x3D;1的线性判别分析</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#p-gt-1%E7%9A%84%E7%BA%BF%E6%80%A7%E5%88%A4%E5%88%AB%E5%88%86%E6%9E%90"><span class="toc-number">3.2.3.</span> <span class="toc-text">p&gt;1的线性判别分析</span></a></li></ol></li></ol></li></ol></div></div></div><header class="post-bg" id="page-header" style="background-image: url(https://i.loli.net/2019/11/10/T7Mu8Aod3egmC4Q.png)"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Leonlist's Blog</a></span><span class="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于</span></a></div></div><span class="toggle-menu close"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></span></span></nav><div id="post-info"><div id="post-title"><div class="posttitle">人工智能概论复习</div></div><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2020-12-04T14:49:37.000Z" title="Created 2020-12-04 22:49:37">2020-12-04</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2020-12-20T09:12:15.545Z" title="Updated 2020-12-20 17:12:15">2020-12-20</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Study/">Study</a></span></div><div class="meta-secondline"> <span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout_post" id="content-inner"><article id="post"><div class="post-content" id="article-container"><h1 id="导论"><a href="#导论" class="headerlink" title="导论"></a>导论</h1><p>统计学习是一套以<strong>理解数据</strong>为目的的庞大工具集。一般有两个用途”一是面向预测的统计模型的建立，二是对一个或多个给定的<strong>输入</strong>估计某个<strong>输出</strong>。</p>
<p><strong>预测</strong>：运用线性回归模型来预测数据</p>
<p><strong>分类</strong>：预测一个非数据变量，即分类或定性的输出</p>
<p><strong>聚类</strong>：不打算预测变量，而是对输入变量的属性进行分类聚合，形成一个个族群</p>
<h1 id="统计学习"><a href="#统计学习" class="headerlink" title="统计学习"></a>统计学习</h1><h2 id="拟合效果检验"><a href="#拟合效果检验" class="headerlink" title="拟合效果检验"></a>拟合效果检验</h2><p>在回归中，最常用的评价准则是均方误差（MSE）:</p>
<script type="math/tex; mode=display">MSE=\frac{1}{n} \sum_{i=1}^{n}(y_i-\hat{f}(x_i))^2</script><script type="math/tex; mode=display">\hat{f}(x_i) $$为预测值

如果预测的响应值与真实的响应值存在实质上的差别，则均方误差会非常大

用训练数据计算的均方误差称为训练均方误差

## 过拟合

过拟合：当模型的光滑度增加时，训练均方误差将降低，但测试均方误差不一定会降低。当所建的模型产生一个较小的训练均方误差，但却有一个较大的测试均方误差，就称该数据过拟合。

出现过拟合的原因：

1. 训练集的数据太少
2. 训练集和新数据的特征分布不一致
3. 训练集中存在噪音。噪音大到模型过分记住了噪音的特征，反而忽略了真实的输入输出间的关系。

## 偏差-方差均衡

期望测试方差能分解成三个基本量的和，分别为：预测值的方差、预测值偏差的方差和误差项$$\varepsilon$$的方差

# 线性回归

## 简单线性回归

非常简单的根据单一预测变量X预测定量响应变量Y的方法，其线性关系为：

$$Y \approx \beta_0+\beta_1X</script><h3 id="估计系数"><a href="#估计系数" class="headerlink" title="估计系数"></a>估计系数</h3><p>我们需要获得系数估计<script type="math/tex">\hat{\beta}_0,\hat{\beta}_1</script>,以使线性模型较好的拟合现有数据。</p>
<p>定义残差平方和（RSS）为：</p>
<script type="math/tex; mode=display">RSS=e_1^2+e_2^2+e_3^2+...e_n^2</script><p>或等价定义为：</p>
<script type="math/tex; mode=display">RSS=（y_1-\hat{\beta}_0-\hat{\beta}_1x_1）^2+（y_2-\hat{\beta}_0-\hat{\beta}_1x_2）^2+...+（y_n-\hat{\beta}_0-\hat{\beta}_1x_n）^2</script><p>通过最小二乘法选择系数使RSS最小，系数即：</p>
<script type="math/tex; mode=display">\hat{\beta_1}=\frac{\sum^{n}\limits_{i=1}{(x_i-\overline{x})(y_i-\overline{y})}}{\sum^{n}\limits_{i=1}{(x_i-\overline{x})^2}}</script><script type="math/tex; mode=display">\hat{\beta_0}=\overline{y}-\hat{\beta_1}\overline{x}</script><p>上式定义了简单线性回归系数的最小二乘估计</p>
<h3 id="评估系数估计值的准确性"><a href="#评估系数估计值的准确性" class="headerlink" title="评估系数估计值的准确性"></a>评估系数估计值的准确性</h3><h3 id="评价模型的准确性"><a href="#评价模型的准确性" class="headerlink" title="评价模型的准确性"></a>评价模型的准确性</h3><p>量化模型拟合数据的程度</p>
<p>判断线性回归的拟合质量通常使用<strong>残差标准误(RSE)</strong>和<strong><script type="math/tex">R^2</script>统计量</strong></p>
<p><strong>残差标准误</strong></p>
<p>每个观测都有误差项<script type="math/tex">\epsilon</script>，因为误差存在，所以不能用X对Y作出完美预测。</p>
<p>RSE是对<script type="math/tex">\epsilon</script>的标准偏差的估计。</p>
<script type="math/tex; mode=display">RSE=\sqrt{\frac{1}{n-2}RSS}=\sqrt{\frac{1}{n-2}\sum^{n}\limits_{i=1}(y_i-\hat{y_i})^2}</script><p>如果RSE值相当小，那么可以认为该模型很好的拟合了数据，如果在多个观测中，<script type="math/tex">y_i、\hat{y_i}</script>相差很大，那么RSE可能是相当大的，表明该模型未能很好的拟合数据</p>
<p><strong><script type="math/tex">R^2</script>统计量</strong></p>
<p>RSE是以Y为标准衡量的，所以并不清楚构成良好的RSE的要素有哪些。<script type="math/tex">R^2</script>统计量采用比例的形式，值在0到1之间，与Y的量无关</p>
<script type="math/tex; mode=display">R^2=\frac{TSS-RSS}{TSS}=1-\frac{RSS}{TSS}</script><script type="math/tex; mode=display">TSS=\sum(y_i-\overline{y})^2$$是总平方和

$$R^2$$测量的是Y的变异中能被X解释的部分所占比例，$$R^2$$统计量接近1说明回归可以解释响应变量的大部分变异。$$R^2$$统计量接近0说明回归没有太多响应变量的变异，这可能因为线性模型是错误的，也可能因为固有误差项$$\sigma^2$$较大，抑或两者皆有。

同时相关性也衡量了X和Y之间的线性关系，这意味着 $$r=Cor(X,Y)$$可以代替$$R^2$$评估线性模型的拟合度。事实上，在简单的线性回归模型中，$$R^2=r^2$$，也就是相关系数的平方与$$R^2$$统计量相等。

## 多元线性回归

多元线性回归模型的形式为：

$$Y \approx \beta_0+\beta_1X_1+\beta_2X_2+...+\beta_pX_p+\epsilon</script><h3 id="估计回归系数"><a href="#估计回归系数" class="headerlink" title="估计回归系数"></a>估计回归系数</h3><p>类似的如下：</p>
<script type="math/tex; mode=display">RSS=\sum^{n}\limits_{i=1}（y_i-\hat{y}_i)^2=\sum^{n}\limits_{i=1}（y_1-\hat{\beta}_0-\hat{\beta}_1x_{i1}-\hat{\beta}_2x_{i2}-...-\hat{\beta}_px_{xp}）^2</script><h3 id="一些重要问题"><a href="#一些重要问题" class="headerlink" title="一些重要问题"></a>一些重要问题</h3><h4 id="响应变量和预测变量之间是否有关系？"><a href="#响应变量和预测变量之间是否有关系？" class="headerlink" title="响应变量和预测变量之间是否有关系？"></a>响应变量和预测变量之间是否有关系？</h4><p>计算<strong>F统计量</strong>：</p>
<script type="math/tex; mode=display">F=\frac{(TSS-RSS)/p}{RSS/(n-p-1)}</script><p>当响应变量与预测变量无关，F统计量应该接近1。</p>
<p>如果F统计量远大于1，那么我们可以认为响应变量与预测变量有关。</p>
<p>那F统计量需要多大才行呢？这取决于样本量n和p的值。如果n很大，即使F统计量略大于1，可能认为有关；如果n较小，需要较大的F统计量证明有关。</p>
<p>似乎，如果任一变量的p值很小，那么至少有一个预测变量与响应变量有关，但当预测变量是数目很大的时候该结论会有缺陷。所以当变量数特别多时，我们甚至不能用最小二乘法拟合多元线性模型，F统计量也无法使用。</p>
<h4 id="预测变量与响应变量的关系"><a href="#预测变量与响应变量的关系" class="headerlink" title="预测变量与响应变量的关系"></a>预测变量与响应变量的关系</h4><p>多元回归分析的第一步是计算F统计量并检查相应的p值。</p>
<p>我们确定哪些变量是和响应变量有关，以建立只包含相关预测变量的模型的任务被称为变量选择。（关于变量选择，蓝珲可能讲不到：）</p>
<h4 id="模型的拟合程度"><a href="#模型的拟合程度" class="headerlink" title="模型的拟合程度"></a>模型的拟合程度</h4><p>两个常见的衡量模型拟合优劣的指标的RSE和<script type="math/tex">R^2</script>.</p>
<p>若<script type="math/tex">R^2</script>值接近1，则表明该模型能解释响应变量的大部分方差。</p>
<p>当RSE值越高，拟合程度越高。</p>
<p>但注意，预测变量增加，RSS在必然减少（拟合程序降低）的情况下，RSE反而会增加。也就是说，变量较多的模型可能有更高的RSE。</p>
<h4 id="如何预测值，预测的准确程度如何？"><a href="#如何预测值，预测的准确程度如何？" class="headerlink" title="如何预测值，预测的准确程度如何？"></a>如何预测值，预测的准确程度如何？</h4><p>一旦拟合出回归模型，就可以预测出响应变量Y，但是预测也有三类不确定性。</p>
<p>第一，系数估计具有不确定性，详见第二章</p>
<p>第二，线性模型是对现实的一种近似，所以存在改进可约误差的机会，线性模型假设是可约误差的来源，称为模型误差。不过我们能忽略这种差异。</p>
<p>第三，模型中不可避免的存在随机误差<script type="math/tex">\epsilon</script>，称为不可约误差。我们用预测区间来估算预测值和真实值之间的差距。预测区间总是比置行区间宽，因为预测区间既包含f(X)的估计误差（可约误差），也包含单个点偏离总体回归平面程度的不确定性（不可约误差）。</p>
<h1 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h1><p>定性变量（比如眼睛的颜色有棕色，蓝色等等，无法定量）</p>
<p>线性回归在定性响应变量情况下是不适用的，因为该响应变量值往往没有自然的程度顺序，顺序改变，预测结果也会改变。</p>
<h2 id="逻辑斯谛回归"><a href="#逻辑斯谛回归" class="headerlink" title="逻辑斯谛回归"></a>逻辑斯谛回归</h2><p>逻辑斯谛回归对Y属于某一类的概率建模而不直接对响应变量Y建模。</p>
<h3 id="逻辑斯谛回归模型"><a href="#逻辑斯谛回归模型" class="headerlink" title="逻辑斯谛回归模型"></a>逻辑斯谛回归模型</h3><script type="math/tex; mode=display">p(X)=\frac{e^{\beta_0+\beta_1X}}{1+e^{\beta_0+\beta_1X}}</script><p>整理上式，可得：</p>
<script type="math/tex; mode=display">\frac{p(X)}{1-p(X)}=e^{\beta_0+\beta_1X}</script><p>其值称为发生比(odd)，取值范围为0到无穷大。</p>
<p>对上式同时取对数，得：</p>
<script type="math/tex; mode=display">\log(\frac{p(X)}{1-p(X)})=\beta_0+\beta_1X</script><p>等式的左边称为<strong>对数发生比</strong>或<strong>分对数</strong>，逻辑斯谛回归可以视为分对数变换下关于X的一个线性模型。</p>
<h3 id="估计回归系数-1"><a href="#估计回归系数-1" class="headerlink" title="估计回归系数"></a>估计回归系数</h3><p>但是回归模型的系数未知，必须通过有效的训练数据估计这些系数。一般采用<strong>极大似然法</strong>拟合逻辑斯谛回归模型</p>
<p>基本思想：寻找$\beta_0+\beta_1$的一个估计，使得到的预测概率最大可能的与实际预测情况接近。</p>
<h3 id="多元逻辑斯谛回归"><a href="#多元逻辑斯谛回归" class="headerlink" title="多元逻辑斯谛回归"></a>多元逻辑斯谛回归</h3><p>对上面式子进行推广：</p>
<script type="math/tex; mode=display">\log(\frac{p(X)}{1-p(X)})=\beta_0+\beta_1X_1+...+\beta_nX_n</script><script type="math/tex; mode=display">p(x)=\frac{e^{\beta_0+\beta_1X_1+...+\beta_pX_p}}{1+e^{\beta_0+\beta_1X_1+...+\beta_pX_p}}</script><p>但在使用一个预测变量做逻辑斯谛回归时，如果其他预测变量与之有关系，那么预测模型会存在风险。与线性回归一样，只用一个预测变量得到的结果可能与多个预测变量得到的结果完全不一样，尤其当这些因素之间存在相关性时更是如此。这种现象称为<strong>混淆现象</strong>。</p>
<h2 id="线性判别分析"><a href="#线性判别分析" class="headerlink" title="线性判别分析"></a>线性判别分析</h2><p>在这类方法中，分别对每种响应分类（给定的Y）建立预测变量X的分布模型，然后运用贝叶斯定理反过来估计$Pr(Y=k|X=x)$</p>
<p>有了逻辑斯谛回归，为什么要用这种方法？</p>
<ol>
<li>当类别的区分度高的时候，逻辑斯谛回归模型的参数估计不够稳定，但线性判别分析不会。</li>
<li>如果样本量N比较小，而且在每一类响应分类中预测变量X近似服从正态分布，那么线性判别分析比逻辑斯谛回归模型更稳定。</li>
<li>响应分类多于两类时，线性判别分析应用更普遍。</li>
</ol>
<h3 id="贝叶斯定理"><a href="#贝叶斯定理" class="headerlink" title="贝叶斯定理"></a>贝叶斯定理</h3><h3 id="p-1的线性判别分析"><a href="#p-1的线性判别分析" class="headerlink" title="p=1的线性判别分析"></a>p=1的线性判别分析</h3><h3 id="p-gt-1的线性判别分析"><a href="#p-gt-1的线性判别分析" class="headerlink" title="p&gt;1的线性判别分析"></a>p&gt;1的线性判别分析</h3><p><strong>例子：</strong></p>
<p>将LDA运用于数据上，根据一个人的信用卡余额和学生身份预测其违约情况。LDA模型对10000个训练样本进行拟合，得到训练错误率为2.75%。但需要注意：</p>
<ol>
<li>训练错误率往往比测试错误率低，而后者才是建模的初衷。如果用分类器去预测一个新个体是否违约，可能效果会很糟糕。因为模型参数的调整过程中主要是使模型在训练数据上表现出较好的效果。而参数p与样本总数n的比值越高，模型越容易出现<strong>过拟合</strong>。</li>
<li>一个普通的零分类器（简单但可能完全无用的分类器）也会达到仅比LDA错误率高一点的效果。</li>
</ol>
<p>表中显示 LDA 一共预测了 104 人会发生违约，但事实上只有 81 人违约而 23 人并没有违约。因此没有违约的 9667 人中只有 23 个人没有被正确地标记，看起来错误率非常低，但是违约的 333 人中，通过的 LDA 后有 252（75.7%）人漏了，所以虽然总的错误率很低，但在违约的人中错误率非常高。所以违约人群 252/333=75.7% 的错误率很可能不被认可。</p>
<table>
  <tr>
    <td colspan="2" rowspan="2">&nbsp;</td>
    <td colspan="3"><center>真实违约情况</center></td>
  </tr>
  <tr>
    <td><center>没有</center></td>
    <td><center>有</center></td>
    <td><center>共计</center></td>
  </tr>
  <tr>
    <td rowspan="3"><center>预测违约情况</center></td>
    <td><center>没有</center></td>
    <td><center>9644</center></td>
    <td><center>252</center></td>
    <td><center>9896</center></td>
  </tr>
  <tr>
    <td><center>有</center></td>
    <td><center>23</center></td>
    <td><center>81</center></td>
    <td><center>104</center></td>
  </tr>
  <tr>
    <td><center>共计</center></td>
    <td><center>9667</center></td>
    <td><center>333</center></td>
    <td><center>10000</center></td>
  </tr>
</table>

<p><strong>灵敏度</strong>：在例子中，就是被正确判别的违约者的比例，即 23/81=24.3%</p>
<p><strong>特异度</strong>：在例子中，被正确判别没有违约人的比例，即 1-23/9667=99.8%</p>
<p><strong>为什么LDA对违约者的分类效果这么差？（灵敏度低）</strong></p>
<p>答：LDA与贝叶斯分类器相似，贝叶斯分类器在不考虑错误来源时，产生的被错误分类的观测数是最少的，那么一些被错误分类的观测是源于将没有违约者分入了违约组里，而另外一些则是将违约者分入了没有违约的组。</p>
<p>但我们希望避免把违约者错误分类，那么可以考虑降低阈值，例如可以将后验概率在20%以上的人纳入违约组。但是会导致总错误率略微增长。</p>
<p>当阈值下降时，违约者的错误率平稳减少，但是未出现违约者的错误率却是增加的。<strong>ROC曲线</strong>可以同时展现所有可能阈值出现的两类错误。</p>
<p><img src= "/img/loading.gif" data-lazy-src="/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%A6%82%E8%AE%BA%E5%A4%8D%E4%B9%A0/image-20201220162057161.png" alt="image-20201220162057161" style="zoom:67%;" /></p>
<p>（上图是错误率关于分类后验概率的阈值的函数。黑色实线是总错误率，蓝色虚线是违约者被错误分类的比例，橙色的点代表的是未违约者被错误分类的比例）</p>
<p>分类器的性能表现是通过ROC曲线下面的面积（AUC）来表示的。一个理想的ROC曲线（蓝色虚线）会紧贴左上角，所以AUC越大，分类器越好。</p>
<p><img src= "/img/loading.gif" data-lazy-src="/images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%A6%82%E8%AE%BA%E5%A4%8D%E4%B9%A0/image-20201220164800832.png" alt="image-20201220164800832" style="zoom:67%;" /></p>
<p>（ROC曲线。<strong>真阳性率</strong>：在给定阈值下，违约者被正确判断的比例。<strong>假阳性率</strong>：同样阈值下，未违约者被错误判断的比例。理想的ROC曲线应该紧贴左上角，即高的真阳性率，低的假阳性率。点虚线代表“没有信息”的分类器）</p>
<p>由上可以看出，不同分类器阈值会改变真阳性率和假阳性率，这也称为<strong>灵敏度</strong>和<strong>1-特异度</strong>。</p>
<table>
  <tr>
    <td colspan="2" rowspan="2">&nbsp;</td>
    <td colspan="3"><center>预测分类</center></td>
  </tr>
  <tr>
    <td><center>-或零</center></td>
    <td><center>+或非零</center></td>
    <td><center>总计</center></td>
  </tr>
  <tr>
    <td rowspan="3"><center>真实分类</center></td>
    <td><center>-或零</center></td>
    <td><center>真阴性值(TN)</center></td>
    <td><center>假阳性值(FP)</center></td>
    <td><center>N</center></td>
  </tr>
  <tr>
    <td><center>+或非零</center></td>
    <td><center>假阴性值(TN)</center></td>
    <td><center>真阳性值(FP)</center></td>
    <td><center>P</center></td>
  </tr>
  <tr>
    <td><center>总计</center></td>
    <td><center>N*</center></td>
    <td><center>P*</center></td>
    <td>&nbsp;</td>
  </tr>
</table>

<p>与假设检验进行结合，将“-”看做零假设，而将“+”看做备择（非零）假设。在例子的背景下，“+”表示违约者，而“-”表示未违约者。</p>
</div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">Leonlist</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="http://yoursite.com/2020/12/04/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%A6%82%E8%AE%BA%E5%A4%8D%E4%B9%A0/">http://yoursite.com/2020/12/04/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%A6%82%E8%AE%BA%E5%A4%8D%E4%B9%A0/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">人工智能</a></div><div class="post_share"><div class="social-share" data-image="https://i.loli.net/2019/11/10/T7Mu8Aod3egmC4Q.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2020/12/09/%E5%85%AD%E7%BA%A7/"><img class="prev-cover" data-lazy-src="https://i.loli.net/2019/11/10/egVhFWopA5mP2Hk.png" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">六级</div></div></a></div><div class="next-post pull-right"><a href="/2020/12/04/Java%E5%A4%8D%E4%B9%A0/"><img class="next-cover" data-lazy-src="https://i.loli.net/2019/11/10/lP3rLNUBaGtSVzc.png" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">Java复习</div></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fas fa-thumbs-up fa-fw"></i><span> Related Articles</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/2020/12/15/人工智能-智能作业批改Aita/" title="人工智能-智能作业批改Aita"><img class="relatedPosts_cover" data-lazy-src="https://i.loli.net/2019/11/10/gcnavZbmepS8d4u.png"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="far fa-calendar-alt fa-fw"></i> 2020-12-15</div><div class="relatedPosts_title">人工智能-智能作业批改Aita</div></div></a></div></div></div></article></main><footer id="footer" data-type="color"><div id="footer-wrap"><div class="copyright">&copy;2020 By Leonlist</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><section id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></section><div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module" defer></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js" async></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    loader: {
      source: {
        '[tex]/amsCd': '[tex]/amscd'
      }
    },
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        addClass: [200,() => {
          document.querySelectorAll('mjx-container:not([display=\'true\']').forEach( node => {
            const target = node.parentNode
            if (!target.classList.contains('has-jax')) {
              target.classList.add('mathjax-overflow')
            }
          })
        }, '', false]
      }
    }
  }
  
  var script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></div></body></html>